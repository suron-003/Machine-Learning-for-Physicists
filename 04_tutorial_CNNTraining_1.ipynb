{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the training of Convolutional Neural Networks (with keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code for the lecture series \"Machine Learning for Physicists\" by Florian Marquardt\n",
    "\n",
    "Lecture 4, Tutorials\n",
    "\n",
    "See https://machine-learning-for-physicists.org and the current course website linked there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to:\n",
    "- visualize the training of convolutional autoencoders using keras\n",
    "\n",
    "The networks are 2D convolutional networks, with the same input and output dimensions, and a bottleneck layer in the middle.\n",
    "\n",
    "You define the network and the type of images that are generated for training â€“ this notebook will help you visualize the training evolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports: numpy and matplotlib and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras: Sequential is the neural-network class, Dense is\n",
    "# the standard network layer\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python.keras import Model\n",
    "from tensorflow.python.keras.layers import Dense, Conv2D, AveragePooling2D, UpSampling2D\n",
    "from tensorflow.python.keras import optimizers # to choose more advanced optimizers like 'adam'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.dpi']=300 # highres display\n",
    "\n",
    "# for subplots within subplots:\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# for nice inset colorbars: (approach changed from lecture 1 'Visualization' notebook)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import InsetPosition\n",
    "\n",
    "# for updating display \n",
    "# (very simple animation)\n",
    "from IPython.display import clear_output\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization routines:\n",
    "from tensorflow import Session\n",
    "def visualize_CNN_training(network,\n",
    "                               image_generator, resolution,\n",
    "                    steps=100, batchsize=10,\n",
    "                              visualize_nsteps=1, plot_img_pixels=3,\n",
    "                          plot_img_cols=10,\n",
    "                          plot_img_rows=5,\n",
    "                          show_intermediate_layers=True):\n",
    "    \"\"\"\n",
    "    Visualize the training of a (2D) convolutional neural network autoencoder.\n",
    "    \n",
    "    network is the network that you have defined using keras.\n",
    "    \n",
    "    'resolution' (called M below) is the image resolution in pixels\n",
    "    \n",
    "    image_generator is the name of a function that\n",
    "    is called like\n",
    "        image_generator(batchsize,x,y)\n",
    "    and which has to return an array of shape\n",
    "        [batchsize,M,M]\n",
    "    that contains randomly generated MxM images (e.g. randomly\n",
    "    placed circles or whatever you want to consider). The\n",
    "    MxM arrays x and y are already filled with coordinates between -1 and 1.\n",
    "    \n",
    "    An example that returns images of randomly placed circles:\n",
    "    \n",
    "    def my_generator(batchsize,x,y):\n",
    "        R=np.random.uniform(size=batchsize)\n",
    "        x0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "        y0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "        return( 1.0*((x[None,:,:]-x0[:,None,None])**2 + (y[None,:,:]-y0[:,None,None])**2 < R[:,None,None]**2) )\n",
    "\n",
    "   \n",
    "    steps is the number of training steps\n",
    "    \n",
    "    batchsize is the number of samples per training step\n",
    "            \n",
    "    visualize_n_steps>1 means skip some steps before\n",
    "    visualizing again (can speed up things)\n",
    "    \n",
    "    show_intermediate_layers==True means show the intermediate activations.\n",
    "    Otherwise show the weights!\n",
    "    \n",
    "    These are always shown in the upper left corner, as a tiled image,\n",
    "    whose properties are determined by:\n",
    "        plot_img_pixels: the resolution for each of the image tiles\n",
    "        plot_img_cols  : the number of columns of images\n",
    "        plot_img_rows  : the number of rows of images\n",
    "    Images (activations or weights) that are larger will be cut off.\n",
    "    If there are more images than fit, the rest will be left out.\n",
    "    The lowest layer starts in the bottom left. For activations, for\n",
    "    each layer one runs through all the channels, and then the images\n",
    "    for the next layer will start. Likewise for weights.\n",
    "    \"\"\"\n",
    "    with Session() as sess:\n",
    "        global y_target # allow access to target from outside\n",
    "\n",
    "        M=resolution\n",
    "\n",
    "        vals=np.linspace(-1,1,M)\n",
    "        x,y=np.meshgrid(vals,vals)\n",
    "\n",
    "        y_test=np.zeros([1,M,M,1],dtype=np.float32)\n",
    "        y_test[:,:,:,0]=image_generator(1,x,y)\n",
    "\n",
    "        y_in=np.zeros([batchsize,M,M,1])\n",
    "\n",
    "        costs=np.zeros(steps)\n",
    "        extractor=get_layer_activation_extractor(network)\n",
    "\n",
    "        for j in range(steps):\n",
    "            # produce samples:\n",
    "            y_in[:,:,:,0]=image_generator(batchsize,x,y).astype(np.float32)\n",
    "            y_target=np.copy(y_in.astype(np.float32)) # autoencoder wants to reproduce its input!\n",
    "\n",
    "            # do one training step on this batch of samples:\n",
    "            costs[j]=network.train_on_batch(y_in,y_target)\n",
    "\n",
    "            # now visualize the updated network:\n",
    "            if j%visualize_nsteps==0:\n",
    "                clear_output(wait=True) # for animation\n",
    "                if j>10:\n",
    "                    cost_max=np.average(costs[0:j])*1.5\n",
    "                else:\n",
    "                    cost_max=costs[0]\n",
    "\n",
    "                # nice layout (needs matplotlib v3)\n",
    "                fig=plt.figure(constrained_layout=True,figsize=(8,4))\n",
    "                gs=fig.add_gridspec(ncols=8,nrows=4)\n",
    "                filter_plot=fig.add_subplot(gs[0:3,0:4])\n",
    "                cost_plot=fig.add_subplot(gs[3,0:4])\n",
    "                test_in_plot=fig.add_subplot(gs[0:2,4:6])\n",
    "                test_out_plot=fig.add_subplot(gs[0:2,6:8])\n",
    "\n",
    "                cost_plot.plot(costs)\n",
    "                cost_plot.set_ylim([0,cost_max])\n",
    "\n",
    "                # test the network on a fixed test image!\n",
    "                y_test_out=network.predict_on_batch(y_test)\n",
    "                test_in_plot.imshow(y_test[0,:,:,0],origin='lower')\n",
    "                test_out_plot.imshow(y_test_out[0,:,:,0],origin='lower')\n",
    "                test_in_plot.axis('off')\n",
    "                test_out_plot.axis('off')\n",
    "\n",
    "                if show_intermediate_layers:\n",
    "                    features=sess.run(extractor(y_test))\n",
    "                    n1=0; n2=0\n",
    "                    max_n1=plot_img_rows\n",
    "                    max_n2=plot_img_cols\n",
    "                    pix=plot_img_pixels\n",
    "                    img=np.full([(pix+1)*max_n1,(pix+1)*max_n2],1.0)\n",
    "                    for feature in features:\n",
    "                        for m in range(feature.shape[-1]):\n",
    "                            w=feature[0,:,:,m]\n",
    "                            ws=np.shape(w)\n",
    "                            if n1<max_n1 and n2<max_n2:\n",
    "                                W=np.zeros([pix,pix])\n",
    "                                if ws[0]<pix:\n",
    "                                    W[0:ws[0],0:ws[0]]=w[:,:]\n",
    "                                else:\n",
    "                                    #W[:,:]=w[0:pix,0:pix]  \n",
    "                                    W=w[0:pix,0:pix]  \n",
    "                                img[n1*(pix+1):(n1+1)*(pix+1)-1,n2*(pix+1):(n2+1)*(pix+1)-1]=W\n",
    "                                n2+=1\n",
    "                                if n2>=max_n2:\n",
    "                                    n2=0\n",
    "                                    n1+=1                \n",
    "                else: # rather, we want the weights! (filters)\n",
    "                    n1=0; n2=0\n",
    "                    max_n1=plot_img_rows\n",
    "                    max_n2=plot_img_cols\n",
    "                    pix=plot_img_pixels\n",
    "                    img=np.zeros([(pix+1)*max_n1,(pix+1)*max_n2])\n",
    "                    for ly in network.layers:\n",
    "                        w=ly.get_weights()\n",
    "                        if w!=[]:\n",
    "                            w=w[0]\n",
    "                            ws=np.shape(w)\n",
    "                            for k1 in range(ws[2]):\n",
    "                                for k2 in range(ws[3]):\n",
    "                                    if n1<max_n1 and n2<max_n2:\n",
    "                                        W=np.zeros([pix,pix])\n",
    "                                        if ws[0]<pix:\n",
    "                                            W[0:ws[0],0:ws[0]]=w[:,:,k1,k2]\n",
    "                                        else:\n",
    "                                            W[:,:]=w[0:pix,0:pix,k1,k2]                            \n",
    "                                        img[n1*(pix+1):(n1+1)*(pix+1)-1,n2*(pix+1):(n2+1)*(pix+1)-1]=W\n",
    "                                        n2+=1\n",
    "                                        if n2>=max_n2:\n",
    "                                            n2=0\n",
    "                                            n1+=1\n",
    "\n",
    "                filter_plot.imshow(img,origin='lower')\n",
    "                filter_plot.axis('off')\n",
    "                plt.show()\n",
    "        print(\"Final cost value (averaged over last 50 batches): \", np.average(costs[-50:]))\n",
    "\n",
    "\n",
    "def print_layers(network, y_in):\n",
    "    \"\"\"\n",
    "    Call this on some test images y_in, to get a print-out of\n",
    "    the layer sizes. Shapes shown are (batchsize,pixels,pixels,channels).\n",
    "    After a call to the visualization routine, y_target will contain\n",
    "    the last set of training images, so you could feed those in here.\n",
    "    \"\"\"\n",
    "    layer_features=get_layer_activations(network,y_in)\n",
    "    for idx,feature in enumerate(layer_features):\n",
    "        s=np.shape(feature)\n",
    "        print(\"Layer \"+str(idx)+\": \"+str(s[1]*s[2]*s[3])+\" neurons / \", s)\n",
    "\n",
    "def get_layer_activation_extractor(network):\n",
    "    return(Model(inputs=network.inputs,\n",
    "                            outputs=[layer.output for layer in network.layers]))\n",
    "\n",
    "def get_layer_activations(network, y_in):\n",
    "    \"\"\"\n",
    "    Call this on some test images y_in, to get the intermediate \n",
    "    layer neuron values. These are returned in a list, with one\n",
    "    entry for each layer (the entries are arrays).\n",
    "    \"\"\"\n",
    "    extractor=get_layer_activation_extractor(network)\n",
    "    layer_features = extractor(y_in)\n",
    "    return(layer_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Reproducing randomly placed circles\n",
    "\n",
    "This is not even an autoencoder: it never shrinks the size of the layers, so in principle it should eventually work perfectly, but it still has to be trained!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(batchsize,x,y):\n",
    "    R=np.random.uniform(size=batchsize)\n",
    "    x0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "    y0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "    return( 1.0*((x[None,:,:]-x0[:,None,None])**2 + (y[None,:,:]-y0[:,None,None])**2 < R[:,None,None]**2) ).astype(np.float32)\n",
    "\n",
    "Net=Sequential()\n",
    "# 3x3 kernel size, 10 channels in first hidden layer:\n",
    "Net.add(Conv2D(10,3,input_shape=(None,None,1),\n",
    "               activation=\"sigmoid\",padding='same'))\n",
    "# 3x3 kernel size, only 1 channel in last hidden layer:\n",
    "Net.add(Conv2D(1,3,activation=\"linear\",padding='same'))\n",
    "Net.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value conv2d_8/kernel\n\t [[Node: conv2d_8/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/Assign\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d_8/kernel)]]\n\nCaused by op 'conv2d_8/kernel/read', defined at:\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-98a5c0adfd20>\", line 10, in <module>\n    activation=\"sigmoid\",padding='same'))\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\sequential.py\", line 164, in add\n    layer(x)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\", line 314, in __call__\n    output = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 699, in __call__\n    self.build(input_shapes)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 144, in build\n    dtype=self.dtype)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable.py\", line 436, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 397, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3795, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv2d_8/kernel\n\t [[Node: conv2d_8/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/Assign\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d_8/kernel)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv2d_8/kernel\n\t [[Node: conv2d_8/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/Assign\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d_8/kernel)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-310750ea362a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m                     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[0mvisualize_nsteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                       plot_img_pixels=50, plot_img_rows=3, plot_img_cols=5)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-90b30e78f722>\u001b[0m in \u001b[0;36mvisualize_CNN_training\u001b[1;34m(network, image_generator, resolution, steps, batchsize, visualize_nsteps, plot_img_pixels, plot_img_cols, plot_img_rows, show_intermediate_layers)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;31m# do one training step on this batch of samples:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m             \u001b[0mcosts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_in\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;31m# now visualize the updated network:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1390\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1392\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2822\u001b[0m     \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdates_op\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2823\u001b[0m     updated = session.run(\n\u001b[1;32m-> 2824\u001b[1;33m         fetches=fetches, feed_dict=feed_dict, **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2825\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value conv2d_8/kernel\n\t [[Node: conv2d_8/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/Assign\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d_8/kernel)]]\n\nCaused by op 'conv2d_8/kernel/read', defined at:\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\asyncio\\events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-98a5c0adfd20>\", line 10, in <module>\n    activation=\"sigmoid\",padding='same'))\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\sequential.py\", line 164, in add\n    layer(x)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\", line 314, in __call__\n    output = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 699, in __call__\n    self.build(input_shapes)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 144, in build\n    dtype=self.dtype)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 546, in add_variable\n    partitioner=partitioner)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable.py\", line 436, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1317, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 1079, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 425, in get_variable\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 394, in _true_getter\n    use_resource=use_resource, constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 786, in _get_single_variable\n    use_resource=use_resource)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2220, in variable\n    use_resource=use_resource)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2210, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variable_scope.py\", line 2193, in default_variable_creator\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 235, in __init__\n    constraint=constraint)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\variables.py\", line 397, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 142, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 3795, in identity\n    \"Identity\", input=input, name=name)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\surya\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value conv2d_8/kernel\n\t [[Node: conv2d_8/kernel/read = Identity[T=DT_FLOAT, _class=[\"loc:@training_2/Adam/Assign\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](conv2d_8/kernel)]]\n"
     ]
    }
   ],
   "source": [
    "visualize_CNN_training(Net, my_generator, 50,\n",
    "                    steps=100, batchsize=10,\n",
    "                              visualize_nsteps=10,\n",
    "                      plot_img_pixels=50, plot_img_rows=3, plot_img_cols=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAABTCAYAAABd90mFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAABHVJREFUeJzt3cFt40gQBVB6sFH4vncnMXAEG+VGYEwSjsKYKKw5GALssWWSUpGsqn7vLEDsZnf1Z5Oi7k6n0wQAwO1+HH0AAABdCFYAAEEEKwCAIIIVAEAQwQoAIIhgBQAQRLACAAgiWAEABBGsAACCCFYAAEEEKwCAIP/s+WU/f/xX+o8Jf73+fzf3me5tXNK+p5fnuANa4fH+YfYz15zDo9oz51J7jdM33dvYvX3TNE2vv/9N0cYlteUrxumbEdr4nh0r+EbWUDVNuY8NYFSCFQB8w0UMawhWcEGFYlrhGAFGIlgBwAwXMSy168PrAJ38vdhe+5Az0IcdK8J1WFwqXZ1WOtYunl6ev+x35wIQrABWmAtPl0IXMIZDbgXOFZ0OOx7sy5hhDwITMGfXHaulV3LnzylidQk6dLO2HqlfMKb0twIFLOYIcQBkkT5YndnFqmePwCNUAZBJmWD1nnAFAGRUMlhNk3BVxZY7Snar2JPxBixRNlhNk3BVxRYLkkWO7IxRGFPpYDVNwlUVj/cPYQuNBYujLB17xiiMq3ywmibhqpJbAlZkOFvyXVVUOtYO5vrb+YCx+a/AHS0JgKMU5fft/K5fRukPajEugUvaBKunl+eUxe6WlwpmbM8WRmknAP21uBWYUcQ7t7y361gVAl+FYwQYSatglSGEbBGGBCwAqKFVsOpOuNpf5h2hzMcG3ZhvLCVYFSNcAUBebR5eP8v6EHukEdqYyeP9Q7pA6/xzjUvj2Hj6nv5hjXbBahTC1bicd9aauzAY8dfIsBW3AgvLtovSmcWGiq754Ysfy3xk7rOWHStYKMMtQUWepSJe9zL6eNuj/V6Q3I8dq+KOXuhHc2ShU2RZKqoujFxfMsy38+7hyOehIjtWDbiy3NcRO1ejnl8LynpbvEdvtPGXsb3n85rx2PjIjhVcwR9Cb0+oWm+rPhvpXGSfbyOdi6oEK7jB1kU4e5HfisVjvY59tvf4rzLfOp7rTgSrJky042xRjPfcEYMljqoxdoa/pubn5RkrCPC+KF9b8KoV9q1YMNbr3mfnubFFOyvPuxGff6ugXbAyyDja32PQ267p4uiFPDJgdZl/R58TPmsXrCAbRQ9iXbtD3HUuCle5tApWow8skwsYjZr3Rv3Pw8PrAIV1f74KqmkTrCR16MFcXkd/cSZk59DqVuDoFFi6yPC/jMCYbq09LXasBArox7wG9hZxQVc+WCm+0Jf5DevY6b1eVN+VvhWo6EJ/X83zX68HHAhqLm1FBtKyO1YmOMAb9RDyKBmsFJHP9AmwJTUGlikXrExugM/URsihTLB6vH9QOC7QL8A0bVcL1BhYLn2wEqgAlouul+ovrHN3Op2OPgYAgBbS71gBAFQhWAEABBGsAACCCFYAAEEEKwCAIIIVAEAQwQoAIIhgBQAQRLACAAgiWAEABBGsAACCCFYAAEEEKwCAIIIVAEAQwQoAIIhgBQAQRLACAAgiWAEABBGsAACCCFYAAEEEKwCAIIIVAEAQwQoAIMgfO8yIlYRadYsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the typical training images (these are available\n",
    "# in the global variable y_target after calling the visualization routine)\n",
    "fig,ax=plt.subplots(ncols=10,nrows=1,figsize=(10,1))\n",
    "for j in range(10):\n",
    "    ax[j].imshow(y_target[j,:,:,0],origin='lower') # the last training images...\n",
    "    ax[j].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Reproducing randomly placed circles with a true autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_generator(batchsize,x,y):\n",
    "    R=np.random.uniform(size=batchsize)\n",
    "    x0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "    y0=np.random.uniform(size=batchsize,low=-1,high=1)\n",
    "    return( 1.0*((x[None,:,:]-x0[:,None,None])**2 + (y[None,:,:]-y0[:,None,None])**2 < R[:,None,None]**2) )\n",
    "\n",
    "Net=Sequential()\n",
    "# 3x3 kernel size, 10 channels in first hidden layer:\n",
    "Net.add(Conv2D(4,5,input_shape=(None,None,1),\n",
    "               activation=\"sigmoid\",padding='same'))\n",
    "Net.add(AveragePooling2D(pool_size=(3,3),padding='same')) # down\n",
    "Net.add(Conv2D(4,5,\n",
    "               activation=\"sigmoid\",padding='same'))\n",
    "Net.add(AveragePooling2D(pool_size=(3,3),padding='same')) # down\n",
    "Net.add(Conv2D(1,3,\n",
    "               activation=\"sigmoid\",padding='same'))\n",
    "Net.add(UpSampling2D(size=(3,3))) # up\n",
    "Net.add(Conv2D(4,5,\n",
    "               activation=\"sigmoid\",padding='same'))\n",
    "Net.add(UpSampling2D(size=(3,3))) # up\n",
    "Net.add(Conv2D(4,5,\n",
    "               activation=\"sigmoid\",padding='same'))\n",
    "Net.add(Conv2D(1,3,activation=\"linear\",padding='same'))\n",
    "Net.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, None, None, 4)     104       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, None, None, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 4)     404       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, None, None, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 1)     37        \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, None, None, 1)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 4)     104       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, None, None, 4)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 4)     404       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, None, None, 1)     37        \n",
      "=================================================================\n",
      "Total params: 1,090\n",
      "Trainable params: 1,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'get_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-e4dad2484761>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m                               \u001b[0mvisualize_nsteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                       \u001b[0mplot_img_cols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_img_rows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                       plot_img_pixels=27)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-90b30e78f722>\u001b[0m in \u001b[0;36mvisualize_CNN_training\u001b[1;34m(network, image_generator, resolution, steps, batchsize, visualize_nsteps, plot_img_pixels, plot_img_cols, plot_img_rows, show_intermediate_layers)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mshow_intermediate_layers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m                     \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m                     \u001b[0mn1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mn2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                     \u001b[0mmax_n1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplot_img_rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \"\"\"\n\u001b[0;32m    313\u001b[0m     \u001b[1;31m# Actually call the layer (optionally building it).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_uses_inputs_arg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    718\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    632\u001b[0m     outputs, _ = self._run_internal_graph(inputs,\n\u001b[0;32m    633\u001b[0m                                           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m                                           mask=masks)\n\u001b[0m\u001b[0;32m    635\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0moutput_shapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m         \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf_layers_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatic_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[0mcache_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_layers_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_list_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_shape_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0moutput_shapes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m         \u001b[0minput_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf_layers_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatic_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[0mcache_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_layers_util\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_list_uid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    870\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_shape_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_shapes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\utils.py\u001b[0m in \u001b[0;36mstatic_shape\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'get_shape'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_CNN_training(Net, my_generator, 9*3,\n",
    "                    steps=500, batchsize=30,\n",
    "                              visualize_nsteps=10,\n",
    "                      plot_img_cols=8, plot_img_rows=4,\n",
    "                      plot_img_pixels=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0: 2916 neurons /  (30, 27, 27, 4)\n",
      "Layer 1: 324 neurons /  (30, 9, 9, 4)\n",
      "Layer 2: 324 neurons /  (30, 9, 9, 4)\n",
      "Layer 3: 36 neurons /  (30, 3, 3, 4)\n",
      "Layer 4: 9 neurons /  (30, 3, 3, 1)\n",
      "Layer 5: 81 neurons /  (30, 9, 9, 1)\n",
      "Layer 6: 324 neurons /  (30, 9, 9, 4)\n",
      "Layer 7: 2916 neurons /  (30, 27, 27, 4)\n",
      "Layer 8: 2916 neurons /  (30, 27, 27, 4)\n",
      "Layer 9: 729 neurons /  (30, 27, 27, 1)\n"
     ]
    }
   ],
   "source": [
    "print_layers(Net,y_target) # find out layer sizes for these training images!\n",
    "# y_target is a global variable that is initialized by the\n",
    "# training visualization routine, and it contains the last few training images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Exercise 1: Try \"relu\" instead of sigmoid!\n",
    "\n",
    "How does the appearance of the pictures change? Inspect and try to interpret the intermediate layer results shown in the upper left part of the figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial Exercise 2: Try this on another type of pictures!\n",
    "\n",
    "Change the my_generator accordingly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework Problem: The Grand Autoencoder Challenge\n",
    "\n",
    "Using the above image generator (which produces random circles), and the above image size 27x27, try to set up an autoencoder network that 'works best'. The rules of the game are:\n",
    "\n",
    "- You may create any kind of network, but the narrowest layer (the bottleneck) must only contain no more than 3 neurons (this defines the 'HARD' version of the challenge). Alternatively, it must only contain no more than 9 neurons (the 'MEDIUM' version of the challenge). When counting neurons, use the routine print_layers (see above!) after running a bit of the training.\n",
    "\n",
    "- You may also use any kind of optimizer, any settings for the learning rate, and any choice of batch size. No pre-processing/post-processing of the input/output of the network is allowed.\n",
    "\n",
    "- The performance will be judged in the following way: when you start fresh training (after freshly initializing the network), what is the cost value after the network has been trained on 30000 images? (e.g. batchsize=30 and steps=1000). Look at the cost value that is printed after the training run is completed. This must be reproducible, i.e. in case of doubt or if there are several contestants with close cost values, the networks will be trained multiple times, to obtain more precise average cost values.\n",
    "\n",
    "- There is also the LONG-TRAINING version of the challenge: what is the cost value you can reach after training over 100,000 images?\n",
    "\n",
    "To be competitive for the MEDIUM challenge, your final cost should be below 0.02.\n",
    "\n",
    "Please post your intermediate achieved cost functions on the forum, so others can get inspired to fine-tune their network structure!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
